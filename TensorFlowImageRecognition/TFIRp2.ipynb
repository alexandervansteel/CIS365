{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats Image Recognition using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display, Image, HTML\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Loading the data from the training and testing folders provided by Kaggle with images of dogs and cats.\n",
    "\n",
    "The image_size can be altered for larger or smaller images. Smaller images will be processed faster, but will lack detail for learning. 224, 150, 96, 64, 32 are all common sizing options. \n",
    "\n",
    "The training, testing, and validating sizes can be altered. The training and validating sizes must be equal to the total size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir='/Users/alexvansteel/Projects/CIS365/TensorFlowImageRecognition/train/'\n",
    "test_dir='/Users/alexvansteel/Projects/CIS365/TensorFlowImageRecognition/test/'\n",
    "\n",
    "# used for scaling/normalization\n",
    "image_size=150; # 150x150.\n",
    "chan=3\n",
    "pixel_depth=255.0  # Number of levels per pixel.\n",
    "\n",
    "# for small-sample testing\n",
    "tv_size_dogs=1000\n",
    "tv_size_cats=1000\n",
    "tv_size_all=2000\n",
    "train_size=1600\n",
    "val_size=400\n",
    "test_size=500\n",
    "\n",
    "if (train_size + val_size != tv_size_all):\n",
    "   print (\"Error, check that train_size + val_size is equal to tv_size_all\")\n",
    "   exit ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Directories\n",
    "Creating the lists of training images for all images, dogs, and cats. As well as creating the list of testing images.\n",
    "\n",
    "Use numpy to create the special arrays with labels for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images=[train_dir+i for i in os.listdir(train_dir)]\n",
    "train_dogs=[train_dir+i for i in os.listdir(train_dir) if 'dog' in i]\n",
    "train_cats=[train_dir+i for i in os.listdir(train_dir) if 'cat' in i]\n",
    "test_images=[test_dir+i for i in os.listdir(test_dir)]\n",
    "\n",
    "train_images=train_dogs[:tv_size_dogs]+train_cats[:tv_size_cats]\n",
    "train_labels=np.array((['dogs']*tv_size_dogs)+(['cats']*tv_size_cats))\n",
    "test_images=test_images[:test_size]\n",
    "test_labels=np.array(['unknownclass']*test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Images\n",
    "Reads the image and ensures that the image is a uniform square. If the image is not a uniform square, adds black space to fill out the image and prevent distortion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_image(file_path):\n",
    "    img=cv2.imread(file_path,cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "    if (img.shape[0]>=img.shape[1]): # height is greater than width\n",
    "       resizeto=(image_size,int(round(image_size*(float(img.shape[1])/img.shape[0]))));\n",
    "    else:\n",
    "       resizeto=(int(round(image_size*(float(img.shape[0])/img.shape[1]))),image_size);\n",
    "\n",
    "    img2=cv2.resize(img,(resizeto[1],resizeto[0]),interpolation=cv2.INTER_CUBIC)\n",
    "    img3=cv2.copyMakeBorder(img2,0,image_size-img2.shape[0],0,image_size-img2.shape[1],cv2.BORDER_CONSTANT,0)\n",
    "\n",
    "    return img3[:,:,::-1]  # turn into rgb format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "Normalizes the colours (R,G,B) independently of one another to prepare the data for learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_data(images):\n",
    "    count=len(images)\n",
    "    data=np.ndarray((count,image_size,image_size,chan),dtype=np.float32)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image=read_image(image_file);\n",
    "        image_data=np.array(image,dtype=np.float32);\n",
    "\n",
    "        image_data[:,:,0]=(image_data[:,:,0].astype(float)-pixel_depth/2)/pixel_depth\n",
    "        image_data[:,:,1]=(image_data[:,:,1].astype(float)-pixel_depth/2)/pixel_depth\n",
    "        image_data[:,:,2]=(image_data[:,:,2].astype(float)-pixel_depth/2)/pixel_depth\n",
    "\n",
    "        data[i]=image_data; # image_data.T\n",
    "        if i%250 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Normalized Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm=prep_data(train_images)\n",
    "test_norm=prep_data(test_images)\n",
    "\n",
    "print('Train shape: {}'.format(train_norm.shape))\n",
    "print('Test shape: {}'.format(test_norm.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "Displays the first three images from the Dogs and Cats after the normalization has been done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_norm[0,:,:,:],interpolation='nearest')\n",
    "plt.figure()\n",
    "plt.imshow(train_norm[1,:,:,:],interpolation='nearest')\n",
    "plt.figure()\n",
    "plt.imshow(train_norm[2,:,:,:],interpolation='nearest')\n",
    "plt.figure()\n",
    "plt.imshow(train_norm[1000,:,:,:],interpolation='nearest')\n",
    "plt.figure()\n",
    "plt.imshow(train_norm[1001,:,:,:],interpolation='nearest')\n",
    "plt.figure()\n",
    "plt.imshow(train_norm[1002,:,:,:],interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training', (1600, 150, 150, 3), (400,))\n",
      "('Validation', (400, 150, 150, 3), (400,))\n",
      "('Test', (500, 150, 150, 3), (500,))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(121)\n",
    "\n",
    "\n",
    "def randomize(dataset,labels):\n",
    "\n",
    "    permutation=np.random.permutation(labels.shape[0])\n",
    "    shuff_dataset=dataset[permutation,:,:,:]\n",
    "    shuff_labels=labels[permutation]\n",
    "\n",
    "    return shuff_dataset,shuff_labels\n",
    "\n",
    "train_dataset_rand,train_labels_rand=randomize(train_norm,train_labels)\n",
    "test_dataset,test_labels=randomize(test_norm,test_labels)\n",
    "\n",
    "valid_dataset=train_dataset_rand[:val_size,:,:,:]\n",
    "valid_labels=train_labels_rand[:val_size]\n",
    "train_dataset=train_dataset_rand[val_size:val_size+train_size,:,:,:]\n",
    "train_labels=train_labels_rand[val_size:val_size+val_size]\n",
    "print('Training',train_dataset.shape,train_labels.shape)\n",
    "print('Validation',valid_dataset.shape,valid_labels.shape)\n",
    "print('Test',test_dataset.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (1600, 150, 150, 3), (400, 2))\n",
      "('Validation set', (400, 150, 150, 3), (400, 2))\n",
      "('Test set', (500, 150, 150, 3), (500, 2))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "num_labels=2\n",
    "num_channels=3 # rg\n",
    "\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset=dataset.reshape((-1,image_size,image_size,num_channels)).astype(np.float32)\n",
    "  labels=(labels=='cats').astype(np.float32); # set dogs to 0 and cats to 1\n",
    "  labels=(np.arange(num_labels)==labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "\n",
    "\n",
    "train_dataset, train_labels=reformat(train_dataset,train_labels)\n",
    "valid_dataset, valid_labels=reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels=reformat(test_dataset, test_labels)\n",
    "print('Training set',train_dataset.shape,train_labels.shape)\n",
    "print('Validation set',valid_dataset.shape,valid_labels.shape)\n",
    "print('Test set',test_dataset.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer 2D Convolution Graph Model\n",
    "The convolution ops sweep a 2-D filter over a batch of images, applying the filter to each window of each image of the appropriate size. It should be noted that although these ops are called \"convolution\", they are strictly speaking \"cross-correlation\" since the filter is combined with an input window without reversing the filter. The convolution then returns a tensor.\n",
    "\n",
    "The pooling ops sweep a rectangular window over the input tensor, computing a reduction operation for each window. The max-pooling used here is a special case of greyscale morphological dilation when the filter assumes all-zero values (a.k.a. flat structuring function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "patch_size=5\n",
    "depth=16\n",
    "num_hidden=64\n",
    "\n",
    "graph=tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset=tf.placeholder(tf.float32,shape=(batch_size,image_size,image_size,num_channels))\n",
    "  tf_train_labels=tf.placeholder(tf.float32,shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset=tf.constant(valid_dataset)\n",
    "  tf_test_dataset=tf.constant(test_dataset)\n",
    "\n",
    "  # variables\n",
    "  kernel_conv1=tf.Variable(tf.truncated_normal([3,3,3,32],dtype=tf.float32,stddev=1e-1),name='weights_conv1')\n",
    "  biases_conv1=tf.Variable(tf.constant(0.0,shape=[32],dtype=tf.float32),trainable=True, name='biases_conv1')\n",
    "  kernel_conv2=tf.Variable(tf.truncated_normal([3,3,32,32],dtype=tf.float32,stddev=1e-1),name='weights_conv2')\n",
    "  biases_conv2=tf.Variable(tf.constant(0.0,shape=[32],dtype=tf.float32),trainable=True,name='biases_conv2')\n",
    "  kernel_conv3=tf.Variable(tf.truncated_normal([3,3,32,64],dtype=tf.float32,stddev=1e-1),name='weights_conv3')\n",
    "  biases_conv3=tf.Variable(tf.constant(0.0,shape=[64],dtype=tf.float32),trainable=True,name='biases_conv3')\n",
    "  fc1w=tf.Variable(tf.truncated_normal([23104,64],dtype=tf.float32,stddev=1e-1),name='weights') # 23104 from pool3.gete_shape () of 19*19*64\n",
    "  fc1b=tf.Variable(tf.constant(1.0,shape=[64],dtype=tf.float32),trainable=True,name='biases')\n",
    "  fc2w=tf.Variable(tf.truncated_normal([64,2],dtype=tf.float32,stddev=1e-1),name='weights')\n",
    "  fc2b=tf.Variable(tf.constant(1.0,shape=[2],dtype=tf.float32),trainable=True,name='biases')\n",
    "\n",
    "\n",
    "  def model(data):\n",
    "     parameters=[]\n",
    "     with tf.name_scope('conv1_1') as scope:\n",
    "         conv=tf.nn.conv2d(data,kernel_conv1,[1,1,1,1],padding='SAME')\n",
    "         out=tf.nn.bias_add(conv,biases_conv1)\n",
    "         conv1_1=tf.nn.relu(out,name=scope)\n",
    "         parameters+=[kernel_conv1,biases_conv1]\n",
    "\n",
    "     # pool1\n",
    "     pool1=tf.nn.max_pool(conv1_1,\n",
    "                            ksize=[1,2,2,1],\n",
    "                            strides=[1,2,2,1],\n",
    "                            padding='SAME',\n",
    "                            name='pool1')\n",
    "\n",
    "     with tf.name_scope('conv2_1') as scope:\n",
    "         conv=tf.nn.conv2d(pool1,kernel_conv2,[1,1,1,1],padding='SAME')\n",
    "         out=tf.nn.bias_add(conv,biases_conv2)\n",
    "         conv2_1=tf.nn.relu(out,name=scope)\n",
    "         parameters+=[kernel_conv2,biases_conv2]\n",
    "\n",
    "     # pool2\n",
    "     pool2=tf.nn.max_pool(conv2_1,\n",
    "                            ksize=[1,2,2,1],\n",
    "                            strides=[1,2,2,1],\n",
    "                            padding='SAME',\n",
    "                            name='pool2')\n",
    "\n",
    "     with tf.name_scope('conv3_1') as scope:\n",
    "         conv=tf.nn.conv2d(pool2,kernel_conv3,[1,1,1,1],padding='SAME')\n",
    "         out=tf.nn.bias_add(conv,biases_conv3)\n",
    "         conv3_1=tf.nn.relu(out,name=scope)\n",
    "         parameters+=[kernel_conv3,biases_conv3]\n",
    "\n",
    "     # pool3\n",
    "     pool3=tf.nn.max_pool(conv3_1,\n",
    "                            ksize=[1,2,2,1],\n",
    "                            strides=[1,2,2,1],\n",
    "                            padding='SAME',\n",
    "                            name='pool3')\n",
    "\n",
    "     # fc1\n",
    "     with tf.name_scope('fc1') as scope:\n",
    "         shape=int(np.prod(pool3.get_shape()[1:])) # except for batch size (the first one), multiple the dimensions\n",
    "         pool3_flat=tf.reshape(pool3,[-1,shape])\n",
    "         fc1l=tf.nn.bias_add(tf.matmul(pool3_flat, fc1w), fc1b)\n",
    "         fc1=tf.nn.relu(fc1l)\n",
    "         parameters+=[fc1w, fc1b]\n",
    "\n",
    "     # fc3\n",
    "     with tf.name_scope('fc3') as scope:\n",
    "         fc2l=tf.nn.bias_add(tf.matmul(fc1,fc2w),fc2b)\n",
    "         parameters+=[fc2w,fc2b]\n",
    "     return fc2l;\n",
    "\n",
    "  # Training computation.\n",
    "  logits=model(tf_train_dataset)\n",
    "  loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=tf_train_labels))\n",
    "\n",
    "  # Optimizer.\n",
    "  optimizer=tf.train.RMSPropOptimizer(0.0001).minimize(loss)\n",
    "\n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction=tf.nn.softmax(logits)\n",
    "  valid_prediction=tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction=tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "('Minibatch loss at step', 0, ':', 0.78864336)\n",
      "Minibatch accuracy: 62.5%\n",
      "('Minibatch loss at step', 50, ':', 0.7771731)\n",
      "Minibatch accuracy: 43.8%\n",
      "Validation accuracy: 46.8%\n",
      "('Minibatch loss at step', 100, ':', 0.70286256)\n",
      "Minibatch accuracy: 43.8%\n",
      "Validation accuracy: 48.2%\n",
      "('Minibatch loss at step', 150, ':', 0.67795044)\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 51.2%\n",
      "('Minibatch loss at step', 200, ':', 0.52479428)\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 56.2%\n",
      "('Minibatch loss at step', 250, ':', 0.61060107)\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 56.8%\n",
      "('Minibatch loss at step', 300, ':', 0.35262322)\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 58.8%\n",
      "('Minibatch loss at step', 350, ':', 0.29634362)\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 54.0%\n",
      "('Minibatch loss at step', 400, ':', 0.27464801)\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 60.2%\n",
      "('Minibatch loss at step', 450, ':', 0.27087396)\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 61.2%\n",
      "('Minibatch loss at step', 500, ':', 0.29063755)\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 59.5%\n",
      "('Minibatch loss at step', 550, ':', 0.086687751)\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 61.0%\n",
      "('Minibatch loss at step', 600, ':', 0.082919881)\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 60.0%\n",
      "('Minibatch loss at step', 650, ':', 0.17733049)\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 60.5%\n",
      "('Minibatch loss at step', 700, ':', 0.14752436)\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 60.5%\n",
      "('Minibatch loss at step', 750, ':', 0.070965871)\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 59.8%\n",
      "('Minibatch loss at step', 800, ':', 0.040964633)\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 60.0%\n",
      "('Minibatch loss at step', 850, ':', 0.049731925)\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 58.2%\n",
      "('Minibatch loss at step', 900, ':', 0.015882336)\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 57.8%\n",
      "('Minibatch loss at step', 950, ':', 0.029345034)\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 60.0%\n",
      "('Minibatch loss at step', 1000, ':', 0.01107374)\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 60.5%\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0*np.sum(np.argmax(predictions,1) == np.argmax(labels,1))/predictions.shape[0])\n",
    "\n",
    "\n",
    "num_steps=1001\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print (\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    offset=(step*batch_size)%(train_labels.shape[0]-batch_size)\n",
    "    batch_data=train_dataset[offset:(offset+batch_size),:,:,:]\n",
    "    batch_labels=train_labels[offset:(offset+batch_size),:]\n",
    "    feed_dict={tf_train_dataset:batch_data,tf_train_labels:batch_labels}\n",
    "    _, l, predictions=session.run([optimizer,loss,train_prediction],feed_dict=feed_dict)\n",
    "    if (step%50 == 0):\n",
    "      print(\"Minibatch loss at step\", step, \":\", l)\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions,batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(),valid_labels))\n",
    "  print (\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
